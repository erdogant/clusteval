<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>How to choose the cluster evaluation method? &mdash; clusteval clusteval documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="_static/css/custom.css?v=e0179649" />

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="_static/jquery.js?v=5d32c60e"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="_static/documentation_options.js?v=8850db52"></script>
        <script src="_static/doctools.js?v=9a2dae69"></script>
        <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Generate data" href="Plots.html" />
    <link rel="prev" title="Installation" href="Installation.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            clusteval
          </a>
              <div class="version">
                2.2.3
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
    
              <p class="caption" role="heading"><span class="caption-text">Background</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Abstract.html">Background</a></li>
<li class="toctree-l1"><a class="reference internal" href="Abstract.html#aim">Aim</a></li>
<li class="toctree-l1"><a class="reference internal" href="Abstract.html#quickstart">Quickstart</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="Installation.html#uninstalling">Uninstalling</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Evaluation Methods</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">How to choose the cluster evaluation method?</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#distance-metric">Distance Metric</a></li>
<li class="toctree-l2"><a class="reference internal" href="#linkage-types">Linkage types</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#derivative-method">Derivative method</a></li>
<li class="toctree-l1"><a class="reference internal" href="#silhouette-score">Silhouette score</a></li>
<li class="toctree-l1"><a class="reference internal" href="#dbindex-score">DBindex score</a></li>
<li class="toctree-l1"><a class="reference internal" href="#dbscan">DBscan</a></li>
<li class="toctree-l1"><a class="reference internal" href="#hdbscan">HDBscan</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Plots</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Plots.html">Generate data</a></li>
<li class="toctree-l1"><a class="reference internal" href="Plots.html#plot">Plot</a></li>
<li class="toctree-l1"><a class="reference internal" href="Plots.html#silhouette-plot">Silhouette plot</a></li>
<li class="toctree-l1"><a class="reference internal" href="Plots.html#scatter-plot">Scatter plot</a></li>
<li class="toctree-l1"><a class="reference internal" href="Plots.html#dendrogram">Dendrogram</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Examples.html">Easy clusters</a></li>
<li class="toctree-l1"><a class="reference internal" href="Examples.html#snake-clusters">Snake clusters</a></li>
<li class="toctree-l1"><a class="reference internal" href="Examples.html#different-density-clusters">Different Density Clusters</a></li>
<li class="toctree-l1"><a class="reference internal" href="Examples.html#clustering-categorical-data">Clustering Categorical Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="Examples.html#detect-the-driving-features">Detect the Driving features</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Save and Load</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Save%20and%20Load.html">Saving</a></li>
<li class="toctree-l1"><a class="reference internal" href="Save%20and%20Load.html#loading">Loading</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Documentation.html">Sponsor</a></li>
<li class="toctree-l1"><a class="reference internal" href="Documentation.html#blog">Blog</a></li>
<li class="toctree-l1"><a class="reference internal" href="Documentation.html#github">Github</a></li>
<li class="toctree-l1"><a class="reference internal" href="Documentation.html#colab-notebook">Colab Notebook</a></li>
<li class="toctree-l1"><a class="reference internal" href="Documentation.html#citing">Citing</a></li>
<li class="toctree-l1"><a class="reference internal" href="Coding%20quality.html">Coding quality</a></li>
<li class="toctree-l1"><a class="reference internal" href="clusteval.clusteval.html">API References</a></li>
</ul>

    <a href= "genindex.html">Index</a>
  
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">clusteval</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">How to choose the cluster evaluation method?</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/Cluster Evaluation.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="how-to-choose-the-cluster-evaluation-method">
<h1>How to choose the cluster evaluation method?<a class="headerlink" href="#how-to-choose-the-cluster-evaluation-method" title="Link to this heading"></a></h1>
<p>With unsupervised clustering we aim to determine “natural” or “data-driven” groups in the data without using apriori knowledge about labels or categories. The challenge of using different unsupervised clustering methods is that it will result in different partitioning of the samples and thus different groupings since each method implicitly impose a structure on the data.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>There is no golden rule to define the optimal number of clusters. It requires investigation, and backtesting.</p>
</div>
<p>The implemented cluster evaluation methods works pretty well in certain scenarios <strong>but</strong> it requires to <strong>understand the mathematical properties of the methods so that it matches with the statistical properties of the data.</strong></p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Investigate the underlying distribution of the data.</p></li>
<li><p>How should clusters “look” like? What is your aim?</p></li>
<li><p>Decide which distance metric, and linkage type is most appropriate for point 2.</p></li>
<li><p>Use the cluster evaluation method that fits best to the above mentioned points.</p></li>
</ol>
</div></blockquote>
<p>As an example: <em>DBScan</em> in combination with the <em>Silhouette evaluation</em> can detect clusters with different densities and shapes while <em>k-means</em> assumes that clusters are <em>convex shaped</em>. Or in other words, when using kmeans, you will always find convex shaped clusters!</p>
<section id="distance-metric">
<h2>Distance Metric<a class="headerlink" href="#distance-metric" title="Link to this heading"></a></h2>
<p><strong>What is a “good” clustering?</strong> Intuitively, we may describe it as a group of samples that are cluttered together. However, it is better to describe clusters with <strong>the distances between the samples</strong>. The most well-known distance metric is the <strong>Euclidean distance</strong>. Although it is set as the default metric in many methods, it is not always the best choice. As an example, in case your dataset is boolean, then it is more wise to use a distance metric such as the hamming distance. Or in other words, use the metric that fits best by the statistical properties of your data.</p>
<table class="docutils align-center" id="id1">
<caption><span class="caption-text">Schematic overview of various distance metrics</span><a class="headerlink" href="#id1" title="Link to this table"></a></caption>
<tbody>
<tr class="row-odd"><td><p><img alt="figC11" src="_images/distance_metrics.png" /></p></td>
</tr>
</tbody>
</table>
</section>
<section id="linkage-types">
<h2>Linkage types<a class="headerlink" href="#linkage-types" title="Link to this heading"></a></h2>
<p>The process of hierarchical clustering involves an approach of grouping samples into a larger cluster. In this process, the distances between two sub-clusters need to be computed for which the different types of linkages describe how the clusters are connected. The most commonly used linkage type is <strong>complete linkage</strong>. Due to the nature of connecting groups, it can handle noisy data. However, if you aim to determine <strong>outliers</strong> or <strong>snake-like clusters</strong>, the <strong>single linkage</strong> is what you need.</p>
<table class="docutils align-center" id="id2">
<caption><span class="caption-text">Linkage types.</span><a class="headerlink" href="#id2" title="Link to this table"></a></caption>
<tbody>
<tr class="row-odd"><td><p><img alt="figC12" src="_images/linkage_types.png" /></p></td>
</tr>
</tbody>
</table>
<p>Choose the metric and linkage type carefully because it directly affects the final clustering results. With this in mind, we can start preprocessing the images.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Single linkage between two clusters is the proximity between their two closest samples. It produces a long chain and is therefore ideal to cluster spherical data but also for outlier detection.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Complete linkage between two clusters is the proximity between their two most distant samples. Intuitively, the two most distant samples cannot be much more dissimilar than other quite dissimilar pairs. It forces clusters to be spherical and have often “compact” contours by their borders, but they are not necessarily compact inside.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Average linkage between two clusters is the arithmetic mean of all the proximities between the objects of one, on one side, and the objects of the other, on the other side.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Centroid linkage is the proximity between the geometric centroids of the clusters.</p>
</div>
</section>
</section>
<section id="derivative-method">
<h1>Derivative method<a class="headerlink" href="#derivative-method" title="Link to this heading"></a></h1>
<p>The <strong>“derivative” method</strong> is built on <code class="docutils literal notranslate"><span class="pre">fcluster()</span></code> from <code class="docutils literal notranslate"><span class="pre">scipy</span></code>. In <code class="docutils literal notranslate"><span class="pre">clusteval</span></code>, it compares each cluster merge’s <strong>height</strong> to the average and normalizes it by the <strong>standard deviation</strong> formed over the depth previous levels. Finally, the <strong>“derivative” method</strong> returns the cluster labels for the optimal cut-off based on the choosen hierarchical clustering method.</p>
<p>Let’s demonstrate this using the previously randomly generated samples.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Libraries</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_blobs</span>
<span class="kn">from</span> <span class="nn">clusteval</span> <span class="kn">import</span> <span class="n">clusteval</span>

<span class="c1"># Generate random data</span>
<span class="n">X</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">centers</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">cluster_std</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="c1"># Intialize model</span>
<span class="n">ce</span> <span class="o">=</span> <span class="n">clusteval</span><span class="p">(</span><span class="n">cluster</span><span class="o">=</span><span class="s1">&#39;agglomerative&#39;</span><span class="p">,</span> <span class="n">evaluate</span><span class="o">=</span><span class="s1">&#39;derivative&#39;</span><span class="p">)</span>

<span class="c1"># Cluster evaluation</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">ce</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># The clustering label can be found in:</span>
<span class="nb">print</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;labx&#39;</span><span class="p">])</span>

<span class="c1"># Make plots</span>
<span class="n">ce</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
<span class="n">ce</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">ce</span><span class="o">.</span><span class="n">plot_silhouette</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="silhouette-score">
<h1>Silhouette score<a class="headerlink" href="#silhouette-score" title="Link to this heading"></a></h1>
<p>The silhouette method is a measure of how similar a sample is to its own cluster (<em>cohesion</em>) compared to other clusters (<em>separation</em>). The scores ranges between [−1, 1], where a high value indicates that the object is well matched to its own cluster and poorly matched to neighboring clusters. It is a <strong>sample-wise approach</strong>, which means that for each sample, a silhouette score is computed and if most samples have a high value, then the clustering configuration is appropriate. If many points have a low or negative value, then the clustering configuration may have too many or too few clusters.</p>
<p>In contrast to the DBindex, the Silhouette score is a sample-wise measure, i.e., measures the average similarity of the samples within a cluster and their distance to the other objects in the other clusters. The silhouette method is independent of the distance metrics which makes it an attractive and versatile method to use.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Higher scores are better.</p>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Independent of the distance metrics.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Libraries</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_blobs</span>
<span class="kn">from</span> <span class="nn">clusteval</span> <span class="kn">import</span> <span class="n">clusteval</span>

<span class="c1"># Generate random data</span>
<span class="n">X</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">centers</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">cluster_std</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="c1"># Intialize model</span>
<span class="n">ce</span> <span class="o">=</span> <span class="n">clusteval</span><span class="p">(</span><span class="n">cluster</span><span class="o">=</span><span class="s1">&#39;agglomerative&#39;</span><span class="p">,</span> <span class="n">evaluate</span><span class="o">=</span><span class="s1">&#39;silhouette&#39;</span><span class="p">)</span>

<span class="c1"># Cluster evaluation</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">ce</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># The clustering label can be found in:</span>
<span class="nb">print</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;labx&#39;</span><span class="p">])</span>

<span class="c1"># Make plots</span>
<span class="n">ce</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
<span class="n">ce</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="dbindex-score">
<h1>DBindex score<a class="headerlink" href="#dbindex-score" title="Link to this heading"></a></h1>
<p><strong>Davies–Bouldin index</strong> can intuitively be described as a measure of the ratio between within-cluster distances, and between cluster distances. The score is bounded between [0, 1]. The lower the value, the tighter the clusters and the seperation between clusters.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Lower scores are better. However, it overshoots frequently. Use the “min_d” and “max_d” parameter to tune for the number of clusters.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Since it measures the distance between clusters centroids it is restricted to using the Euclidean distances.</p>
</div>
<table class="docutils align-center" id="id3">
<caption><span class="caption-text">The DB index for k number of clusters is defined as :</span><a class="headerlink" href="#id3" title="Link to this table"></a></caption>
<tbody>
<tr class="row-odd"><td><p><img alt="figCE2" src="_images/dbindex_eq1.png" /></p></td>
<td><p><img alt="figCE3" src="_images/dbindex_eq2.jpg" /></p></td>
</tr>
</tbody>
</table>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Libraries</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_blobs</span>
<span class="kn">from</span> <span class="nn">clusteval</span> <span class="kn">import</span> <span class="n">clusteval</span>

<span class="c1"># Generate random data</span>
<span class="n">X</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">centers</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">cluster_std</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="c1"># Intialize model</span>
<span class="n">ce</span> <span class="o">=</span> <span class="n">clusteval</span><span class="p">(</span><span class="n">cluster</span><span class="o">=</span><span class="s1">&#39;agglomerative&#39;</span><span class="p">,</span> <span class="n">evaluate</span><span class="o">=</span><span class="s1">&#39;dbindex&#39;</span><span class="p">)</span>

<span class="c1"># Cluster evaluation</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">ce</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># The clustering label can be found in:</span>
<span class="nb">print</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;labx&#39;</span><span class="p">])</span>

<span class="c1"># Make plots</span>
<span class="n">ce</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
<span class="n">ce</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">ce</span><span class="o">.</span><span class="n">dendrogram</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="dbscan">
<h1>DBscan<a class="headerlink" href="#dbscan" title="Link to this heading"></a></h1>
<p><strong>Density-Based Spatial Clustering of Applications with Noise</strong> is an clustering approach that finds core samples of high density and expands clusters from them. This works especially good when having samples which contains clusters of similar density.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Libraries</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_blobs</span>
<span class="kn">from</span> <span class="nn">clusteval</span> <span class="kn">import</span> <span class="n">clusteval</span>

<span class="c1"># Generate random data</span>
<span class="n">X</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">centers</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">cluster_std</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="c1"># Intialize model</span>
<span class="n">ce</span> <span class="o">=</span> <span class="n">clusteval</span><span class="p">(</span><span class="n">cluster</span><span class="o">=</span><span class="s1">&#39;dbscan&#39;</span><span class="p">)</span>

<span class="c1"># Parameters can be changed for dbscan:</span>
<span class="c1"># ce = clusteval(cluster=&#39;dbscan&#39;, params_dbscan={&#39;epsres&#39; :100, &#39;norm&#39;:True})</span>

<span class="c1"># Cluster evaluation</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">ce</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># The clustering label can be found in:</span>
<span class="nb">print</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;labx&#39;</span><span class="p">])</span>

<span class="c1"># Make plots</span>
<span class="n">ce</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
<span class="n">ce</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="hdbscan">
<h1>HDBscan<a class="headerlink" href="#hdbscan" title="Link to this heading"></a></h1>
<p><strong>Hierarchical Density-Based Spatial Clustering of Applications with Noise</strong> is an extension of the <strong>DBscan</strong> method which hierarchically finds core samples of high density and expands clusters from them.</p>
<p>Let’s evaluate the results using <strong>hdbscan</strong>.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>hdbscan
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Libraries</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_blobs</span>
<span class="kn">from</span> <span class="nn">clusteval</span> <span class="kn">import</span> <span class="n">clusteval</span>

<span class="c1"># Generate random data</span>
<span class="n">X</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">centers</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">cluster_std</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="c1"># Determine the optimal number of clusters</span>
<span class="n">ce</span> <span class="o">=</span> <span class="n">clusteval</span><span class="p">(</span><span class="n">cluster</span><span class="o">=</span><span class="s1">&#39;hdbscan&#39;</span><span class="p">)</span>

<span class="c1"># Make plots</span>
<span class="n">ce</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
<span class="n">ce</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
<hr>
<center>
        <script async src="https://media.ethicalads.io/media/client/ethicalads.min.js"></script>
        <!-- Show an image ad -->
        <!-- <div data-ea-publisher="erdogantgithubio" data-ea-type="image"></div> -->
        <div data-ea-publisher="erdogantgithubio" data-ea-type="image" data-ea-style="stickybox"></div>
</center>
<hr></section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="Installation.html" class="btn btn-neutral float-left" title="Installation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="Plots.html" class="btn btn-neutral float-right" title="Generate data" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Erdogan Taskesen.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>